{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "%matplotlib inline\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "import statsmodels.formula.api as sm\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# set default theme to seaborn for plotly.express\n",
    "pio.templates.default = \"simple_white\"\n",
    "# change default size\n",
    "pio.templates[pio.templates.default].layout[\"height\"] = 600\n",
    "pio.templates[pio.templates.default].layout[\"width\"] = 800\n",
    "pio.templates[\"simple_white\"].layout.autosize = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "- Do the example notebooks for\n",
    "    - grid search [X]\n",
    "    - derivative based line search \n",
    "    - db trust region\n",
    "    - db free trust region\n",
    "    - db free direct search\n",
    "\n",
    "- Create quizzes in objectives materials for all the above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize how classes of optimizers work\n",
    "\n",
    "- All algorithms are very simplified compared to real algorithms\n",
    "- All visualizations only use 1 dimensional function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_function_plotly():\n",
    "    x_grid = np.linspace(0, 20, 100)\n",
    "    y_grid = [example_criterion(x) for x in x_grid]\n",
    "    fig = px.line(x=x_grid, y=y_grid)\n",
    "    # remove axis names\n",
    "    fig.update_xaxes(title_text=\"\")\n",
    "    fig.update_yaxes(title_text=\"\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_function():\n",
    "    x_grid = np.linspace(0, 20, 100)\n",
    "    y_grid = [example_criterion(x) for x in x_grid]\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.lineplot(x=x_grid, y=y_grid, ax=ax)\n",
    "    sns.despine()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_history(evaluated_points, argmin):\n",
    "    \"\"\"Plot the function and all evaluated points.\"\"\"\n",
    "    fig, ax = plot_function()\n",
    "    sns.rugplot(evaluated_points, ax=ax)\n",
    "    ax.plot([argmin], [example_criterion(argmin)], marker=\"*\", color=\"firebrick\")\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def _check_argmin(argmin):\n",
    "    if isinstance(argmin, np.ndarray):\n",
    "        if len(argmin) == 1:\n",
    "            argmin = argmin[0]\n",
    "        else:\n",
    "            raise ValueError(\"argmin should be a float or a np.ndarray of length 1\")\n",
    "    return argmin\n",
    "\n",
    "\n",
    "def _fix_if_argmin_is_in_evaluated_points(evaluated_points, argmin):\n",
    "    if argmin in evaluated_points:\n",
    "        evaluated_points = evaluated_points[:-1]\n",
    "\n",
    "\n",
    "def plot_history_plotly(evaluated_points, argmin):\n",
    "    _fix_if_argmin_is_in_evaluated_points(evaluated_points, argmin)\n",
    "\n",
    "    argmin = _check_argmin(argmin)\n",
    "\n",
    "    x_grid = np.linspace(0, 20, 100)\n",
    "    y_grid = [example_criterion(x) for x in x_grid]\n",
    "    fig = px.line(x=x_grid, y=y_grid)\n",
    "    # remove axis names\n",
    "    fig.update_xaxes(title_text=\"\")\n",
    "    fig.update_yaxes(title_text=\"\")\n",
    "\n",
    "    fig.add_scatter(\n",
    "        x=[argmin],\n",
    "        y=[example_criterion(argmin)],\n",
    "        mode=\"markers\",\n",
    "        marker={\"size\": 12, \"color\": \"red\"},\n",
    "        name=\"Final evaluation\",\n",
    "        marker_symbol=\"star\",\n",
    "    )\n",
    "\n",
    "    fig.add_scatter(\n",
    "        x=evaluated_points,\n",
    "        y=[example_criterion(x) for x in evaluated_points],\n",
    "        mode=\"markers\",\n",
    "        marker={\"size\": 4, \"color\": \"black\"},\n",
    "        name=\"Evaluations\",\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def minimize_with_history(fun, x0, method, jac=None, hess=None):\n",
    "    \"\"\"Dumbed down scipy minimize that returns full history.\n",
    "\n",
    "    This is really only meant for illustration in this notebook. In particular,\n",
    "    the following restrictions apply:\n",
    "\n",
    "    - Only works for 1 dimensional problems\n",
    "    - does not support all arguments\n",
    "\n",
    "    \"\"\"\n",
    "    history = []\n",
    "\n",
    "    def wrapped_fun(x, history=history):\n",
    "        history.append(_unpack_x(x))\n",
    "        return fun(x)\n",
    "\n",
    "    res = minimize(wrapped_fun, x0, method=method, jac=jac, hess=hess)\n",
    "    res.history = history\n",
    "    return res\n",
    "\n",
    "\n",
    "def taylor_expansion(x, x0, radius):\n",
    "    \"\"\"Evaluate taylor expansion around x0 at x.\"\"\"\n",
    "    x = _unpack_x(x)\n",
    "    x0 = _unpack_x(x0)\n",
    "    f = example_criterion(x0)\n",
    "    f_prime = example_gradient(x0)\n",
    "    f_double_prime = example_hessian(x0)\n",
    "\n",
    "    if radius <= 0:\n",
    "        raise ValueError(\"radius should be positive\")\n",
    "\n",
    "    diff = x - x0\n",
    "    return f + f_prime * diff + f_double_prime * 0.5 * diff**2\n",
    "\n",
    "\n",
    "def regression_surrogate(x, x0, radius):\n",
    "    \"\"\"Evaluate a regression based surrogate model at x.\n",
    "\n",
    "    x0 and radius define the trust region in which evaluation points are sampled.\n",
    "\n",
    "    \"\"\"\n",
    "    x = _unpack_x(x)\n",
    "    x0 = _unpack_x(x0)\n",
    "    deviations = [-radius, 0, radius]\n",
    "\n",
    "    evaluations = [example_criterion(x0 + deviation) for deviation in deviations]\n",
    "    df = pd.DataFrame()\n",
    "    df[\"x\"] = deviations\n",
    "    df[\"y\"] = evaluations\n",
    "    params = sm.ols(formula=\"y ~ x + I(x**2)\", data=df).fit().params\n",
    "    vec = np.array([1, (x - x0), (x - x0) ** 2])\n",
    "    return params @ vec\n",
    "\n",
    "\n",
    "def plot_trust_region_algo(x0, radius, surrogate_func):\n",
    "    fig, ax = plot_function()\n",
    "    x0 = _unpack_x(x0)\n",
    "    trust_x_grid = np.linspace(x0 - radius, x0 + radius, 50)\n",
    "    partialed = functools.partial(surrogate_func, x0=x0, radius=radius)\n",
    "    trust_y_grid = [partialed(x) for x in trust_x_grid]\n",
    "    argmin_index = np.argmin(trust_y_grid)\n",
    "    argmin = trust_x_grid[argmin_index]\n",
    "\n",
    "    ax.plot([argmin], [partialed(np.array([argmin]))], marker=\"*\", color=\"firebrick\")\n",
    "    ax.plot(\n",
    "        [argmin],\n",
    "        [example_criterion(np.array([argmin]))],\n",
    "        marker=\"*\",\n",
    "        color=\"green\",\n",
    "    )\n",
    "\n",
    "    sns.lineplot(x=trust_x_grid, y=trust_y_grid, ax=ax)\n",
    "\n",
    "    new_x = (\n",
    "        x0\n",
    "        if example_criterion([argmin]) >= example_criterion(x0)\n",
    "        else np.array([argmin])\n",
    "    )\n",
    "\n",
    "    if surrogate_func == taylor_expansion:\n",
    "        x_values = [x0]\n",
    "    else:\n",
    "        x_values = [x0 - radius, x0, x0 + radius]\n",
    "\n",
    "    sns.rugplot(x_values, ax=ax)\n",
    "    return fig, ax, new_x\n",
    "\n",
    "\n",
    "def plot_trust_region_algo_plotly(x0, radius, surrogate_func):\n",
    "    fig = plot_function_plotly()\n",
    "    x0 = _unpack_x(x0)\n",
    "    trust_x_grid = np.linspace(x0 - radius, x0 + radius, 50)\n",
    "    partialed = functools.partial(surrogate_func, x0=x0, radius=radius)\n",
    "    trust_y_grid = [partialed(x) for x in trust_x_grid]\n",
    "    argmin_index = np.argmin(trust_y_grid)\n",
    "    argmin = trust_x_grid[argmin_index]\n",
    "\n",
    "    fig.add_scatter(\n",
    "        x=[argmin],\n",
    "        y=[partialed(np.array([argmin]))],\n",
    "        mode=\"markers\",\n",
    "        marker={\"size\": 12, \"color\": \"red\"},\n",
    "        name=\"Approximate next evaluation\",\n",
    "        marker_symbol=\"star\",\n",
    "    )\n",
    "    fig.add_scatter(\n",
    "        x=[argmin],\n",
    "        y=[example_criterion(np.array([argmin]))],\n",
    "        mode=\"markers\",\n",
    "        marker={\"size\": 12, \"color\": \"green\"},\n",
    "        name=\"True next evaluation\",\n",
    "        marker_symbol=\"star\",\n",
    "    )\n",
    "\n",
    "    fig.add_scatter(\n",
    "        x=trust_x_grid,\n",
    "        y=trust_y_grid,\n",
    "        mode=\"lines\",\n",
    "        name=\"Surrogate model\",\n",
    "        line={\"color\": \"darkorange\", \"width\": 2},\n",
    "    )\n",
    "\n",
    "    new_x = (\n",
    "        x0\n",
    "        if example_criterion([argmin]) >= example_criterion(x0)\n",
    "        else np.array([argmin])\n",
    "    )\n",
    "\n",
    "    if surrogate_func == taylor_expansion:\n",
    "        x_values = [x0]\n",
    "    else:\n",
    "        x_values = [x0 - radius, x0, x0 + radius]\n",
    "\n",
    "    fig.add_scatter(\n",
    "        x=x_values,\n",
    "        y=[example_criterion(x) for x in x_values],\n",
    "        mode=\"markers\",\n",
    "        marker={\"size\": 4, \"color\": \"black\"},\n",
    "        name=\"Initial evaluation\",\n",
    "    )\n",
    "\n",
    "    return fig, new_x\n",
    "\n",
    "\n",
    "def plot_direct_search(x0, other):\n",
    "    fig, ax = plot_function()\n",
    "    x0 = _unpack_x(x0)\n",
    "    other = _unpack_x(other)\n",
    "\n",
    "    x_values = [x0, other]\n",
    "    evaluations = [example_criterion(x) for x in x_values]\n",
    "\n",
    "    argmin_index = np.argmin(evaluations)\n",
    "    argmin = x_values[argmin_index]\n",
    "\n",
    "    ax.plot([argmin], [example_criterion(argmin)], marker=\"*\", color=\"firebrick\")\n",
    "    sns.rugplot(x_values, ax=ax)\n",
    "\n",
    "    return fig, ax, argmin\n",
    "\n",
    "\n",
    "def plot_direct_search_plotly(x0, other):\n",
    "    fig = plot_function_plotly()\n",
    "    x0 = _unpack_x(x0)\n",
    "    other = _unpack_x(other)\n",
    "\n",
    "    x_values = [x0, other]\n",
    "    evaluations = [example_criterion(x) for x in x_values]\n",
    "\n",
    "    argmin_index = np.argmin(evaluations)\n",
    "    argmin = x_values[argmin_index]\n",
    "\n",
    "    # remove argmin from x_values\n",
    "    x_values = x_values[:argmin_index] + x_values[argmin_index + 1 :]\n",
    "\n",
    "    fig.add_scatter(\n",
    "        x=[argmin],\n",
    "        y=[example_criterion(argmin)],\n",
    "        mode=\"markers\",\n",
    "        marker={\"size\": 12, \"color\": \"red\"},\n",
    "        name=\"Next evaluation\",\n",
    "        marker_symbol=\"star\",\n",
    "    )\n",
    "\n",
    "    fig.add_scatter(\n",
    "        x=x_values,\n",
    "        y=[example_criterion(x) for x in x_values],\n",
    "        mode=\"markers\",\n",
    "        marker={\"size\": 4, \"color\": \"black\"},\n",
    "        name=\"Initial evaluation\",\n",
    "    )\n",
    "\n",
    "    return fig, argmin\n",
    "\n",
    "\n",
    "def plot_line_search(x0):\n",
    "    fig, ax = plot_function()\n",
    "    x0 = _unpack_x(x0)\n",
    "\n",
    "    function_value = example_criterion(x0)\n",
    "    gradient_value = example_gradient(x0)\n",
    "    approx_hessian_value = np.clip(example_hessian(x0), 0.1, np.inf)\n",
    "    base_step = -1 / approx_hessian_value * gradient_value\n",
    "\n",
    "    gradient_grid = [x0 - 2, x0, x0 + 2]\n",
    "    gradient_evals = [\n",
    "        function_value - 2 * gradient_value,\n",
    "        function_value,\n",
    "        function_value + 2 * gradient_value,\n",
    "    ]\n",
    "    sns.lineplot(x=gradient_grid, y=gradient_evals, ax=ax)\n",
    "\n",
    "    new_value = np.inf\n",
    "    x_values = [x0]\n",
    "    evaluations = [function_value]\n",
    "    alpha = 1\n",
    "    while new_value >= function_value:\n",
    "        new_x = x0 + alpha * base_step\n",
    "        new_value = example_criterion(new_x)\n",
    "        x_values.append(new_x)\n",
    "        evaluations.append(new_value)\n",
    "\n",
    "    sns.rugplot(x_values, ax=ax)\n",
    "    ax.plot([new_x], [new_value], marker=\"*\", color=\"firebrick\")\n",
    "    return fig, ax, new_x\n",
    "\n",
    "\n",
    "def plot_line_search_plotly(x0):\n",
    "    fig = plot_function_plotly()\n",
    "    x0 = _unpack_x(x0)\n",
    "\n",
    "    function_value = example_criterion(x0)\n",
    "    gradient_value = example_gradient(x0)\n",
    "    approx_hessian_value = np.clip(example_hessian(x0), 0.1, np.inf)\n",
    "    base_step = -1 / approx_hessian_value * gradient_value\n",
    "\n",
    "    gradient_grid = [x0 - 2, x0, x0 + 2]\n",
    "    gradient_evals = [\n",
    "        function_value - 2 * gradient_value,\n",
    "        function_value,\n",
    "        function_value + 2 * gradient_value,\n",
    "    ]\n",
    "    # make it dark orange\n",
    "    fig.add_scatter(\n",
    "        x=gradient_grid,\n",
    "        y=gradient_evals,\n",
    "        mode=\"lines\",\n",
    "        name=\"Gradient\",\n",
    "        line={\"color\": \"darkorange\", \"width\": 2},\n",
    "    )\n",
    "\n",
    "    new_value = np.inf\n",
    "    x_values = [x0]\n",
    "    evaluations = [function_value]\n",
    "    alpha = 1\n",
    "    while new_value >= function_value:\n",
    "        new_x = x0 + alpha * base_step\n",
    "        new_value = example_criterion(new_x)\n",
    "        x_values.append(new_x)\n",
    "        evaluations.append(new_value)\n",
    "\n",
    "    # mark the point of the initial evaluation with a circle\n",
    "    fig.add_scatter(\n",
    "        x=[x0],\n",
    "        y=[function_value],\n",
    "        mode=\"markers\",\n",
    "        marker={\"size\": 8, \"color\": \"green\"},\n",
    "        name=\"Initial point\",\n",
    "    )\n",
    "\n",
    "    # mark the point of the next step with a star\n",
    "    fig.add_scatter(\n",
    "        x=[new_x],\n",
    "        y=[new_value],\n",
    "        mode=\"markers\",\n",
    "        marker={\"size\": 12, \"color\": \"blue\"},\n",
    "        name=\"Next initial point\",\n",
    "        marker_symbol=\"star\",\n",
    "    )\n",
    "\n",
    "    # mark the true minimum with a star\n",
    "    fig.add_scatter(\n",
    "        x=[argmin],\n",
    "        y=[example_criterion(np.array([argmin]))],\n",
    "        mode=\"markers\",\n",
    "        marker={\"size\": 12, \"color\": \"red\"},\n",
    "        name=\"Global minimum\",\n",
    "        marker_symbol=\"star\",\n",
    "    )\n",
    "\n",
    "    return fig, new_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a function\n",
    "\n",
    "- The function has a local minimum at 9.594 and a global minimum at 17.37\n",
    "- It is twice continuously differentiable\n",
    "- It is not convex\n",
    "- In some areas it can be reasonably well approximated by a quadratic function, it others it cannot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS = [\n",
    "    9.003014962148157,\n",
    "    -3.383000146393776,\n",
    "    -0.6037887934635748,\n",
    "    1.6984454347036886,\n",
    "    -0.9447426232680957,\n",
    "    0.2669069434366247,\n",
    "    -0.04446368897497234,\n",
    "    0.00460781796708519,\n",
    "    -0.0003000790127508276,\n",
    "    1.1934114174145725e-05,\n",
    "    -2.6471293419570505e-07,\n",
    "    2.5090819960943964e-09,\n",
    "]\n",
    "\n",
    "\n",
    "def example_criterion(x):\n",
    "    x = _unpack_x(x)\n",
    "    exponents = np.arange(len(WEIGHTS))\n",
    "    return WEIGHTS @ x**exponents\n",
    "\n",
    "\n",
    "def example_gradient(x):\n",
    "    x = _unpack_x(x)\n",
    "    exponents = np.arange(len(WEIGHTS))\n",
    "    return (WEIGHTS * exponents) @ x ** (exponents - 1).clip(0)\n",
    "\n",
    "\n",
    "def example_hessian(x):\n",
    "    x = _unpack_x(x)\n",
    "    exponents = np.arange(len(WEIGHTS))\n",
    "    return (WEIGHTS * exponents * (exponents - 1)) @ x ** (exponents - 2).clip(0)\n",
    "\n",
    "\n",
    "def _unpack_x(x):\n",
    "    if hasattr(x, \"__len__\"):\n",
    "        assert len(x) == 1\n",
    "\n",
    "    if isinstance(x, pd.DataFrame):\n",
    "        res = x[\"value\"].to_numpy()[0]\n",
    "    elif isinstance(x, pd.Series):\n",
    "        res = x.to_numpy()[0]\n",
    "    elif isinstance(x, np.ndarray | list | tuple):\n",
    "        res = x[0]\n",
    "    else:\n",
    "        res = float(x)\n",
    "    return res\n",
    "\n",
    "\n",
    "start_x = np.array([2])\n",
    "fig = plot_function()\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "- Needs bounds on the parameter (0 to 20 in our case)\n",
    "- Desired precision determines number of grid points\n",
    "- Very feasible in one dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 100\n",
    "grid = np.linspace(0, 20, n_points)\n",
    "evaluations = [example_criterion(x) for x in grid]\n",
    "argmin_index = np.argmin(evaluations)\n",
    "argmin = grid[argmin_index]\n",
    "\n",
    "fig = plot_history_plotly(grid, argmin)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative based line search algorithm\n",
    "\n",
    "### Basic Idea\n",
    "\n",
    "- Use first derivative to get search direction\n",
    "- Use approximated second derivative to guess step length\n",
    "- Use a line search algorithm to see how far to go in the search direction\n",
    "    - Line search stays a 1d problem even with many parameters\n",
    "    - Only solved approximately\n",
    "    - Quite complicated if you really want to understand it\n",
    "    - Most of the time accepts the first guess\n",
    "- Accept the new parameter and go back to start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ilustration\n",
    "\n",
    "This is just an illustration of the principle. The Hessian approximation is just the real Hessian clipped at 0.1 so it works for non-convex functions. This is neither smart, nor computationally feasible for large problems. The line search accepts the initial guess if it yields an improvement and shortens the step length otherwise. While this is guaranteed to yield an improvement at some point, it is not a smart line search algorithm. Real algorithms approximate the hessian in a better way and use a smarter line search algorithm. You should never implement an optimization algorithm yourself. Leave it to experts unless you are a very good programmer, have read a few books on optimization algorithms and a very special problem that cannot be solved with existing algorithms. \n",
    "\n",
    "### Initial evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, new_x = plot_line_search_plotly(start_x)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- large gradient, low curvature\n",
    "- make a big step\n",
    "\n",
    "### Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, x = plot_line_search_plotly(new_x)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- large gradient, large curvature\n",
    "- make a smaller step\n",
    "\n",
    "### Iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, x = plot_line_search_plotly(x)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- very small gradient, low curvature\n",
    "- make a very small step\n",
    "\n",
    "### Iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step is very small, due to low gradient and low curvature\n",
    "fig, x = plot_line_search_plotly(x)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- very small gradient, low curvature\n",
    "- make a very small step\n",
    "\n",
    "### Iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, x = plot_line_search_plotly(x)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- medium-sized gradient, low curvature\n",
    "- make a larger step again\n",
    "\n",
    "### Iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, x = plot_line_search_plotly(x)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- medium-sized gradient, larger curvature \n",
    "- make a small step\n",
    "\n",
    "### Iteration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, x = plot_line_search_plotly(x)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reverse direction due to gradient\n",
    "\n",
    "### Iteration 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, x = plot_line_search_plotly(x)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convergence based on gradient ≈ zero criterion\n",
    "\n",
    "### Notes\n",
    "\n",
    "- A big advantage over algorithms you will see later is that this has no tuning parameters.\n",
    "- Using hessian for step length is much better than standard gradient descent. \n",
    "- In very high dimensional problems, standard gradient descent can nevertheless be computationally better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A real algorithm: L-BFGS-B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize_with_history(\n",
    "    example_criterion,\n",
    "    start_x,\n",
    "    method=\"L-BFGS-B\",\n",
    "    jac=example_gradient,\n",
    ")\n",
    "len(res.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_history_plotly(res.history, res.x)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative based trust region algorithm\n",
    "\n",
    "\n",
    "### Basic Idea\n",
    "\n",
    "1. Fix a trust region radius\n",
    "1. Construct a Taylor expansion of the function based on function value, gradient, and (approximation to) Hessian \n",
    "  \n",
    "   The Taylor expansion\n",
    "   - approximates the function well within trust region if radius is not too large\n",
    "   - is a quadratic function that it easy to optimize \n",
    "\n",
    "1. Minimize the Taylor expansion within the trust region\n",
    "1. Evaluate function again at the argmin of the Taylor expansion\n",
    "1. Compare expected and actual improvement\n",
    "1. Accept the new parameters if actual improvement is good enough\n",
    "1. Potentially modify the trust region radius \n",
    "  \n",
    "   **This is a very important and very complicated step**\n",
    "\n",
    "1. Go back to 2.\n",
    "\n",
    "\n",
    "## Illustration\n",
    "\n",
    "This is just an illustration of the principle. The trust region radius is updated manually to simulate a real algorithm.\n",
    "\n",
    "Note that a real algorithm is quite complex to implement. You should never do that yourself. Leave it to experts unless\n",
    "- you are a very good programmer,\n",
    "- you have read a few books on optimization algorithms,\n",
    "-  and you have a very special problem that cannot be solved with existing algorithms. \n",
    "\n",
    "### Initial evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, x_0 = plot_trust_region_algo_plotly(start_x, 2, taylor_expansion)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- orange line has approximation\n",
    "- expected improvement: difference between f(x0) and minimum of the orange line\n",
    "- actual improvement: difference beween f(x0) and f(x)\n",
    "- since actual improvement / expected improvement large (>1 even)\n",
    "  - accept the new point → midpoint of new trust region\n",
    "  - increase trust region radius\n",
    "  \n",
    "### Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, x_1 = plot_trust_region_algo_plotly(x_0, 3, taylor_expansion)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- actual improvement / expected improvement < 1, but still large\n",
    "- accept new point, increase trust region\n",
    "\n",
    "### Iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, x_2 = plot_trust_region_algo_plotly(x_1, 4, taylor_expansion)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- actual improvement / expected improvement is negative\n",
    "- Do not new accept point\n",
    "- Decrease trust region radius\n",
    "\n",
    "### Iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, x_3 = plot_trust_region_algo_plotly(x_2, 2, taylor_expansion)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- actual improvement / expected improvement around 1\n",
    "- accept new point, increase trust region\n",
    "\n",
    "### Iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, x_4 = plot_trust_region_algo_plotly(x_3, 3, taylor_expansion)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- actual improvement / expected improvement around 1\n",
    "- accept new point, increase trust region\n",
    "\n",
    "### Iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, x_5 = plot_trust_region_algo_plotly(\n",
    "    x_4,\n",
    "    radius=3,\n",
    "    surrogate_func=taylor_expansion,\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convergence somewhere here\n",
    "\n",
    "\n",
    "### Notes\n",
    "\n",
    "- Most of the time, the approximation was not very good but sent us in the right direction\n",
    "- After a successful iteration, the trust region radius is increased\n",
    "- At some point it becomes too large and needs to be decreased\n",
    "- From now on the algorithm would converge soon because of a zero gradient\n",
    "- Even when it converges, the trust region radius does not shrink to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A real algorithm: Trust-NCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize_with_history(\n",
    "    example_criterion,\n",
    "    start_x,\n",
    "    method=\"trust-ncg\",\n",
    "    jac=example_gradient,\n",
    "    hess=example_hessian,\n",
    ")\n",
    "fig = plot_history_plotly(res.history, res.x)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize_with_history(\n",
    "    example_criterion,\n",
    "    start_x,\n",
    "    method=\"trust-ncg\",\n",
    "    jac=example_gradient,\n",
    "    hess=example_hessian,\n",
    ")\n",
    "plot_history(res.history, res.x)\n",
    "len(res.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative free trust region algorithm\n",
    "\n",
    "### Basic Idea\n",
    "\n",
    "- Similar to derivative based trust region algorithm.\n",
    "- Instead of Taylor expansion, use a surrogate model based on interpolation or regression.\n",
    "    - Interpolation: Function is evaluated at exactly as many points as you need to fit the model.\n",
    "    - Regression: Function is evaluated at more points than you strictly need. Better for noisy functions.\n",
    "    - In general: Evaluation points are spread further out than for numerical derivatives.\n",
    "- How the evaluation points are determined is complicated. It is also crucial for the efficiency of the algorithm.\n",
    "\n",
    "## Illustration\n",
    "\n",
    "This is just an illustration of the principle. The trust region radius is updated manually to simulate a real algorithm.\n",
    "\n",
    "Note that a real algorithm is quite complex to implement. You should never do that yourself. Leave it to experts unless\n",
    "- you are a very good programmer,\n",
    "- you have read a few books on optimization algorithms,\n",
    "-  and you have a very special problem that cannot be solved with existing algorithms. \n",
    "\n",
    "### Initial evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, x = plot_trust_region_algo(\n",
    "    start_x,\n",
    "    radius=2,\n",
    "    surrogate_func=regression_surrogate,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- orange line has approximation\n",
    "- expected improvement: difference between f(x0) and minimum of the orange line\n",
    "- actual improvement: difference beween f(x0) and f(x)\n",
    "- since actual improvement / expected improvement large (around 1)\n",
    "  - accept the new point → midpoint of new trust region\n",
    "  - increase trust region radius\n",
    "  \n",
    "### Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, x = plot_trust_region_algo(x, radius=3, surrogate_func=regression_surrogate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- actual improvement / expected improvement large (around 1) again\n",
    "- accept new point, increase trust region\n",
    "\n",
    "### Iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, x = plot_trust_region_algo(x, radius=4, surrogate_func=regression_surrogate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- actual improvement / expected improvement large (around 1)\n",
    "- but step length is small\n",
    "- accept new point, decrease trust region\n",
    "\n",
    "### Iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, x = plot_trust_region_algo(x, radius=2, surrogate_func=regression_surrogate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- actual improvement / expected improvement reasonable\n",
    "- step length is small\n",
    "- accept new point, decrease trust region\n",
    "\n",
    "### Iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, x = plot_trust_region_algo(x, radius=1, surrogate_func=regression_surrogate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- actual improvement / expected improvement large (around 1)\n",
    "- step length is large\n",
    "- accept new point, increase trust region\n",
    "\n",
    "### Iteration 5+\n",
    "\n",
    "- will continue around here until optimum is reached\n",
    "- you get the idea\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "- The fit is generally better than the gradient based trust region algorithm\n",
    "- By construction especially at corners of trust region\n",
    "- Choose between the two based on computation speed\n",
    "    - If you have fast closed form derivatives, use the derivative based algorithm\n",
    "    - If you only have numerical derivatives, use this instead\n",
    "- Points at which the function has been evaluated before can be re-used to save function evaluations\n",
    "- Since no gradient is available, algorithm will continue until trust region radius shrinks to zero\n",
    "- It's intuitively very clear how this can work for noisy functions if enough evaluations are used for each surrogate model\n",
    "\n",
    "\n",
    "### A real algorithm: Cobyla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize_with_history(example_criterion, start_x, method=\"Cobyla\")\n",
    "plot_history(res.history, res.x)\n",
    "len(res.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative free direct search algorithm\n",
    "\n",
    "### Basic Idea\n",
    "\n",
    "- Explore parameter space around current point systematically and accept the best value\n",
    "- Also called pattern search because the points at which the function is evaluated form a pattern\n",
    "- Easiest example for one dimensional problems:\n",
    "    - Evaluate function at current point and one other point\n",
    "    - Switch direction of other point if you got a decrease\n",
    "    - Make steps larger after success\n",
    "    - Make steps smaller after failure\n",
    "\n",
    "\n",
    "## Illustration\n",
    "\n",
    "This is just an illustration of the principle. The trust region radius is updated manually to simulate a real algorithm.\n",
    "\n",
    "Note that a real algorithm is quite complex to implement. You should never do that yourself. Leave it to experts unless\n",
    "- you are a very good programmer,\n",
    "- you have read a few books on optimization algorithms,\n",
    "-  and you have a very special problem that cannot be solved with existing algorithms. \n",
    "\n",
    "### Initial evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, x_0 = plot_direct_search_plotly(start_x, start_x - 2)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = start_x\n",
    "fig, ax, x = plot_direct_search(x, x - 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- candidate value worse than original value\n",
    "- do not accept candidate value, switch direction\n",
    "\n",
    "### Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, x = plot_direct_search(x, x + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, x_1 = plot_direct_search_plotly(x_0, x_0 + 2)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- candidate value better than original value\n",
    "- accept candidate value, increase step length\n",
    "\n",
    "### Iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, x_2 = plot_direct_search_plotly(x_1, x_1 + 3)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, x = plot_direct_search(x, x + 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- candidate value better than original value\n",
    "- accept candidate value, increase step length\n",
    "\n",
    "### Iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, x = plot_direct_search(x, x + 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- candidate value worse than original value\n",
    "- do not accept new point, make step smaller\n",
    "\n",
    "### Iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, x = plot_direct_search(x, x + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- from here on it becomes complex because we already know from iteration 3 that we will do worse further right\n",
    "- will eventually converge around here\n",
    "\n",
    "### Notes\n",
    "\n",
    "- Adjusting the step size and switching to promising directions is complicated in real algorithms\n",
    "- Direct search algorithms only use the information which function value is smallest, not by how much\n",
    "- Makes them slow but robust to small amounts of noise\n",
    "- It does not help for large amounts of noise\n",
    "- Most famous example is the Nelder-Mead algorithm which is widely used, but seldomly the best choice\n",
    "\n",
    "\n",
    "### A real example: Nelder Mead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize_with_history(example_criterion, start_x, method=\"Nelder-Mead\")\n",
    "plot_history(res.history, res.x)\n",
    "len(res.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
